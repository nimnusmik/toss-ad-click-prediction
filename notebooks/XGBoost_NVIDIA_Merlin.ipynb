{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NVIDIA Merlin XGBoost\n",
    "Complete implementation with proper memory management and debugging outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Environment configured\n"
     ]
    }
   ],
   "source": [
    "# Environment setup\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"✅ Environment configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ nvtabular       NOT INSTALLED (required: ≥23.08.00)\n",
      "❌ cudf            NOT INSTALLED (required: ≥23.10)\n",
      "❌ cupy            NOT INSTALLED (required: ≥13.6)\n",
      "❌ xgboost         NOT INSTALLED (required: ≥3.0)\n",
      "❌ dask            NOT INSTALLED (required: ≥2023.9)\n",
      "✅ pandas          2.3.2           (required: ≥1.5)\n",
      "✅ numpy           2.2.6           (required: ≥1.24)\n",
      "✅ scikit-learn    1.7.2           (required: ≥1.7)\n",
      "✅ psutil          7.0.0           (required: ≥5.9)\n",
      "✅ pyarrow         21.0.0          (required: ≥12.0)\n",
      "\n",
      "❌ Missing libraries: nvtabular, cudf, cupy, xgboost, dask\n",
      "Please install them using conda or pip\n"
     ]
    }
   ],
   "source": [
    "# Required libraries and versions\n",
    "required_libs = {\n",
    "    'nvtabular': '23.08.00',\n",
    "    'cudf': '23.10',      # Prefix match\n",
    "    'cupy': '13.6',       # Prefix match  \n",
    "    'xgboost': '3.0',     # Minimum version\n",
    "    'dask': '2023.9',\n",
    "    'pandas': '1.5',\n",
    "    'numpy': '1.24',\n",
    "    'scikit-learn': '1.7',\n",
    "    'psutil': '5.9',      # 5.9.1 works fine (used in working code)\n",
    "    'pyarrow': '12.0'     # 12.0.1 works fine (used in working code)\n",
    "}\n",
    "\n",
    "# Check installed versions\n",
    "import importlib\n",
    "import warnings\n",
    "\n",
    "# Suppress deprecation warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "    try:\n",
    "        import pkg_resources\n",
    "    except:\n",
    "        pkg_resources = None\n",
    "\n",
    "missing_libs = []\n",
    "all_good = True\n",
    "\n",
    "for lib, required_version in required_libs.items():\n",
    "    try:\n",
    "        # Map library names for import\n",
    "        import_name = lib\n",
    "        if lib == 'scikit-learn':\n",
    "            import_name = 'sklearn'\n",
    "        \n",
    "        # Check if library is installed\n",
    "        module = importlib.import_module(import_name)\n",
    "        \n",
    "        # Get installed version\n",
    "        try:\n",
    "            if hasattr(module, '__version__'):\n",
    "                installed_version = module.__version__\n",
    "            elif pkg_resources:\n",
    "                installed_version = pkg_resources.get_distribution(lib).version\n",
    "            else:\n",
    "                installed_version = 'unknown'\n",
    "        except:\n",
    "            installed_version = 'unknown'\n",
    "        \n",
    "        # Check version compatibility\n",
    "        req_major = required_version.split('.')[0]\n",
    "        inst_version_parts = installed_version.split('.')\n",
    "        inst_major = inst_version_parts[0] if installed_version != 'unknown' else ''\n",
    "        \n",
    "        # More lenient version check\n",
    "        if installed_version == 'unknown':\n",
    "            print(f\"⚠️  {lib:15} {installed_version:15} (required: ≥{required_version})\")\n",
    "        elif float(inst_major) >= float(req_major) if inst_major.isdigit() and req_major.isdigit() else installed_version.startswith(required_version[:3]):\n",
    "            print(f\"✅ {lib:15} {installed_version:15} (required: ≥{required_version})\")\n",
    "        else:\n",
    "            print(f\"⚠️  {lib:15} {installed_version:15} (required: ≥{required_version}) - but should work\")\n",
    "        \n",
    "    except ImportError:\n",
    "        missing_libs.append(lib)\n",
    "        print(f\"❌ {lib:15} NOT INSTALLED (required: ≥{required_version})\")\n",
    "        all_good = False\n",
    "\n",
    "# Report\n",
    "if missing_libs:\n",
    "    print(f\"\\n❌ Missing libraries: {', '.join(missing_libs)}\")\n",
    "    print(\"Please install them using conda or pip\")\n",
    "elif all_good:\n",
    "    print(\"\\n✅ All required libraries are installed and compatible!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /root/toss-ad-click-prediction/toss-ml-venv/lib/python3.10/site-packages (from -r /root/toss-ad-click-prediction/requirements.txt (line 1)) (2.3.2)\n",
      "Requirement already satisfied: scikit-learn in /root/toss-ad-click-prediction/toss-ml-venv/lib/python3.10/site-packages (from -r /root/toss-ad-click-prediction/requirements.txt (line 2)) (1.7.2)\n",
      "Requirement already satisfied: tqdm in /root/toss-ad-click-prediction/toss-ml-venv/lib/python3.10/site-packages (from -r /root/toss-ad-click-prediction/requirements.txt (line 3)) (4.67.1)\n",
      "Requirement already satisfied: torch in /root/toss-ad-click-prediction/toss-ml-venv/lib/python3.10/site-packages (from -r /root/toss-ad-click-prediction/requirements.txt (line 4)) (2.8.0)\n",
      "Requirement already satisfied: seaborn in /root/toss-ad-click-prediction/toss-ml-venv/lib/python3.10/site-packages (from -r /root/toss-ad-click-prediction/requirements.txt (line 5)) (0.13.2)\n",
      "Requirement already satisfied: pyarrow in /root/toss-ad-click-prediction/toss-ml-venv/lib/python3.10/site-packages (from -r /root/toss-ad-click-prediction/requirements.txt (line 6)) (21.0.0)\n",
      "Requirement already satisfied: fastparquet in /root/toss-ad-click-prediction/toss-ml-venv/lib/python3.10/site-packages (from -r /root/toss-ad-click-prediction/requirements.txt (line 7)) (2024.11.0)\n",
      "Requirement already satisfied: polars in /root/toss-ad-click-prediction/toss-ml-venv/lib/python3.10/site-packages (from -r /root/toss-ad-click-prediction/requirements.txt (line 8)) (1.33.1)\n",
      "Collecting nvtabular\n",
      "  Downloading nvtabular-23.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (284 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.5/284.5 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting cudf\n",
      "  Downloading cudf-0.6.1.post1.tar.gz (1.1 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting cupy\n",
      "  Downloading cupy-13.6.0.tar.gz (3.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m74.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting xgboost\n",
      "  Downloading xgboost-3.0.5-py3-none-manylinux_2_28_x86_64.whl (94.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 MB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tzdata>=2022.7 in /root/toss-ad-click-prediction/toss-ml-venv/lib/python3.10/site-packages (from pandas->-r /root/toss-ad-click-prediction/requirements.txt (line 1)) (2025.2)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /root/toss-ad-click-prediction/toss-ml-venv/lib/python3.10/site-packages (from pandas->-r /root/toss-ad-click-prediction/requirements.txt (line 1)) (2.2.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /root/toss-ad-click-prediction/toss-ml-venv/lib/python3.10/site-packages (from pandas->-r /root/toss-ad-click-prediction/requirements.txt (line 1)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /root/toss-ad-click-prediction/toss-ml-venv/lib/python3.10/site-packages (from pandas->-r /root/toss-ad-click-prediction/requirements.txt (line 1)) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /root/toss-ad-click-prediction/toss-ml-venv/lib/python3.10/site-packages (from scikit-learn->-r /root/toss-ad-click-prediction/requirements.txt (line 2)) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /root/toss-ad-click-prediction/toss-ml-venv/lib/python3.10/site-packages (from scikit-learn->-r /root/toss-ad-click-prediction/requirements.txt (line 2)) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /root/toss-ad-click-prediction/toss-ml-venv/lib/python3.10/site-packages (from scikit-learn->-r /root/toss-ad-click-prediction/requirements.txt (line 2)) (3.6.0)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /root/toss-ad-click-prediction/toss-ml-venv/lib/python3.10/site-packages (from torch->-r /root/toss-ad-click-prediction/requirements.txt (line 4)) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /root/toss-ad-click-prediction/toss-ml-venv/lib/python3.10/site-packages (from torch->-r /root/toss-ad-click-prediction/requirements.txt (line 4)) (11.3.3.83)\n",
      "Requirement already satisfied: triton==3.4.0 in /root/toss-ad-click-prediction/toss-ml-venv/lib/python3.10/site-packages (from torch->-r /root/toss-ad-click-prediction/requirements.txt (line 4)) (3.4.0)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /root/toss-ad-click-prediction/toss-ml-venv/lib/python3.10/site-packages (from torch->-r /root/toss-ad-click-prediction/requirements.txt (line 4)) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /root/toss-ad-click-prediction/toss-ml-venv/lib/python3.10/site-packages (from torch->-r /root/toss-ad-click-prediction/requirements.txt (line 4)) (12.8.90)\n",
      "Requirement already satisfied: jinja2 in /root/toss-ad-click-prediction/toss-ml-venv/lib/python3.10/site-packages (from torch->-r /root/toss-ad-click-prediction/requirements.txt (line 4)) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /root/toss-ad-click-prediction/toss-ml-venv/lib/python3.10/site-packages (from torch->-r /root/toss-ad-click-prediction/requirements.txt (line 4)) (0.7.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /root/toss-ad-click-prediction/toss-ml-venv/lib/python3.10/site-packages (from torch->-r /root/toss-ad-click-prediction/requirements.txt (line 4)) (4.15.0)\n",
      "Requirement already satisfied: filelock in /root/toss-ad-click-prediction/toss-ml-venv/lib/python3.10/site-packages (from torch->-r /root/toss-ad-click-prediction/requirements.txt (line 4)) (3.19.1)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /root/toss-ad-click-prediction/toss-ml-venv/lib/python3.10/site-packages (from torch->-r /root/toss-ad-click-prediction/requirements.txt (line 4)) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /root/toss-ad-click-prediction/toss-ml-venv/lib/python3.10/site-packages (from torch->-r /root/toss-ad-click-prediction/requirements.txt (line 4)) (1.13.1.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /root/toss-ad-click-prediction/toss-ml-venv/lib/python3.10/site-packages (from torch->-r /root/toss-ad-click-prediction/requirements.txt (line 4)) (2.27.3)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /root/toss-ad-click-prediction/toss-ml-venv/lib/python3.10/site-packages (from torch->-r /root/toss-ad-click-prediction/requirements.txt (line 4)) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /root/toss-ad-click-prediction/toss-ml-venv/lib/python3.10/site-packages (from torch->-r /root/toss-ad-click-prediction/requirements.txt (line 4)) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /root/toss-ad-click-prediction/toss-ml-venv/lib/python3.10/site-packages (from torch->-r /root/toss-ad-click-prediction/requirements.txt (line 4)) (11.7.3.90)\n",
      "Requirement already satisfied: fsspec in /root/toss-ad-click-prediction/toss-ml-venv/lib/python3.10/site-packages (from torch->-r /root/toss-ad-click-prediction/requirements.txt (line 4)) (2025.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /root/toss-ad-click-prediction/toss-ml-venv/lib/python3.10/site-packages (from torch->-r /root/toss-ad-click-prediction/requirements.txt (line 4)) (1.14.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /root/toss-ad-click-prediction/toss-ml-venv/lib/python3.10/site-packages (from torch->-r /root/toss-ad-click-prediction/requirements.txt (line 4)) (12.8.93)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /root/toss-ad-click-prediction/toss-ml-venv/lib/python3.10/site-packages (from torch->-r /root/toss-ad-click-prediction/requirements.txt (line 4)) (10.3.9.90)\n",
      "Requirement already satisfied: networkx in /root/toss-ad-click-prediction/toss-ml-venv/lib/python3.10/site-packages (from torch->-r /root/toss-ad-click-prediction/requirements.txt (line 4)) (3.4.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /root/toss-ad-click-prediction/toss-ml-venv/lib/python3.10/site-packages (from torch->-r /root/toss-ad-click-prediction/requirements.txt (line 4)) (12.8.93)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /root/toss-ad-click-prediction/toss-ml-venv/lib/python3.10/site-packages (from triton==3.4.0->torch->-r /root/toss-ad-click-prediction/requirements.txt (line 4)) (65.5.0)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /root/toss-ad-click-prediction/toss-ml-venv/lib/python3.10/site-packages (from seaborn->-r /root/toss-ad-click-prediction/requirements.txt (line 5)) (3.10.6)\n",
      "Requirement already satisfied: packaging in /root/toss-ad-click-prediction/toss-ml-venv/lib/python3.10/site-packages (from fastparquet->-r /root/toss-ad-click-prediction/requirements.txt (line 7)) (25.0)\n",
      "Requirement already satisfied: cramjam>=2.3 in /root/toss-ad-click-prediction/toss-ml-venv/lib/python3.10/site-packages (from fastparquet->-r /root/toss-ad-click-prediction/requirements.txt (line 7)) (2.11.0)\n",
      "Collecting merlin-dataloader>=23.4.0\n",
      "  Downloading merlin-dataloader-23.8.0.tar.gz (46 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.9/46.9 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting merlin-core>=23.4.0\n",
      "  Downloading merlin-core-23.8.0.tar.gz (142 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.1/142.1 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting fastrlock>=0.5\n",
      "  Using cached fastrlock-0.8.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_28_x86_64.whl (53 kB)\n",
      "Requirement already satisfied: pillow>=8 in /root/toss-ad-click-prediction/toss-ml-venv/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn->-r /root/toss-ad-click-prediction/requirements.txt (line 5)) (11.3.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /root/toss-ad-click-prediction/toss-ml-venv/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn->-r /root/toss-ad-click-prediction/requirements.txt (line 5)) (1.4.9)\n",
      "Requirement already satisfied: cycler>=0.10 in /root/toss-ad-click-prediction/toss-ml-venv/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn->-r /root/toss-ad-click-prediction/requirements.txt (line 5)) (0.12.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /root/toss-ad-click-prediction/toss-ml-venv/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn->-r /root/toss-ad-click-prediction/requirements.txt (line 5)) (1.3.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /root/toss-ad-click-prediction/toss-ml-venv/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn->-r /root/toss-ad-click-prediction/requirements.txt (line 5)) (4.59.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /root/toss-ad-click-prediction/toss-ml-venv/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn->-r /root/toss-ad-click-prediction/requirements.txt (line 5)) (3.2.4)\n",
      "Collecting numba>=0.54\n",
      "  Downloading numba-0.61.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m85.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting dask-cuda>=22.12.0\n",
      "  Downloading dask_cuda-25.8.0-py3-none-any.whl (157 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m157.5/157.5 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting betterproto<2.0.0\n",
      "  Downloading betterproto-1.2.5.tar.gz (26 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting distributed>=2022.11.1\n",
      "  Downloading distributed-2025.9.1-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m65.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting npy-append-array\n",
      "  Downloading npy_append_array-0.9.19-py3-none-any.whl (10 kB)\n",
      "Collecting dask>=2022.11.1\n",
      "  Downloading dask-2025.9.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m77.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pynvml<11.5,>=11.0.0\n",
      "  Downloading pynvml-11.4.1-py3-none-any.whl (46 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.0/47.0 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pandas\n",
      "  Downloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m86.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting protobuf>=3.0.0\n",
      "  Downloading protobuf-6.32.1-cp39-abi3-manylinux2014_x86_64.whl (322 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.0/322.0 kB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow-metadata>=1.2.0\n",
      "  Downloading tensorflow_metadata-1.17.2-py3-none-any.whl (31 kB)\n",
      "Requirement already satisfied: six>=1.5 in /root/toss-ad-click-prediction/toss-ml-venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->-r /root/toss-ad-click-prediction/requirements.txt (line 1)) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /root/toss-ad-click-prediction/toss-ml-venv/lib/python3.10/site-packages (from sympy>=1.13.3->torch->-r /root/toss-ad-click-prediction/requirements.txt (line 4)) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /root/toss-ad-click-prediction/toss-ml-venv/lib/python3.10/site-packages (from jinja2->torch->-r /root/toss-ad-click-prediction/requirements.txt (line 4)) (3.0.2)\n",
      "Collecting grpclib\n",
      "  Downloading grpclib-0.4.8-py3-none-any.whl (76 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.3/76.3 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting stringcase\n",
      "  Downloading stringcase-1.2.0.tar.gz (3.0 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting importlib_metadata>=4.13.0\n",
      "  Downloading importlib_metadata-8.7.0-py3-none-any.whl (27 kB)\n",
      "Collecting toolz>=0.10.0\n",
      "  Downloading toolz-1.0.0-py3-none-any.whl (56 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.4/56.4 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting click>=8.1\n",
      "  Downloading click-8.2.1-py3-none-any.whl (102 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.2/102.2 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyyaml>=5.3.1 in /root/toss-ad-click-prediction/toss-ml-venv/lib/python3.10/site-packages (from dask>=2022.11.1->merlin-core>=23.4.0->nvtabular->-r /root/toss-ad-click-prediction/requirements.txt (line 9)) (6.0.2)\n",
      "Collecting cloudpickle>=3.0.0\n",
      "  Downloading cloudpickle-3.1.1-py3-none-any.whl (20 kB)\n",
      "Collecting partd>=1.4.0\n",
      "  Downloading partd-1.4.2-py3-none-any.whl (18 kB)\n",
      "Collecting dask-cuda>=22.12.0\n",
      "  Downloading dask_cuda-25.6.0-py3-none-any.whl (138 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.4/138.4 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading dask_cuda-25.4.0-py3-none-any.whl (135 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.9/135.9 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading dask_cuda-25.2.0-py3-none-any.whl (133 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.9/133.9 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting rapids-dask-dependency==25.2.*\n",
      "  Downloading rapids_dask_dependency-25.2.0-py3-none-any.whl (22 kB)\n",
      "Collecting dask-cuda>=22.12.0\n",
      "  Downloading dask_cuda-24.12.0-py3-none-any.whl (134 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.4/134.4 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting rapids-dask-dependency==24.12.*\n",
      "  Downloading rapids_dask_dependency-24.12.0-py3-none-any.whl (15 kB)\n",
      "Collecting zict>=2.0.0\n",
      "  Downloading zict-3.0.0-py2.py3-none-any.whl (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.3/43.3 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting dask-expr==1.1.19\n",
      "  Downloading dask_expr-1.1.19-py3-none-any.whl (244 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.5/244.5 kB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting distributed>=2022.11.1\n",
      "  Downloading distributed-2024.11.2-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m66.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting dask>=2022.11.1\n",
      "  Downloading dask-2024.11.2-py3-none-any.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m71.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tblib>=1.6.0\n",
      "  Downloading tblib-3.1.0-py3-none-any.whl (12 kB)\n",
      "Collecting locket>=1.0.0\n",
      "  Downloading locket-1.0.0-py2.py3-none-any.whl (4.4 kB)\n",
      "Requirement already satisfied: tornado>=6.2.0 in /root/toss-ad-click-prediction/toss-ml-venv/lib/python3.10/site-packages (from distributed>=2022.11.1->merlin-core>=23.4.0->nvtabular->-r /root/toss-ad-click-prediction/requirements.txt (line 9)) (6.5.2)\n",
      "Requirement already satisfied: urllib3>=1.26.5 in /root/toss-ad-click-prediction/toss-ml-venv/lib/python3.10/site-packages (from distributed>=2022.11.1->merlin-core>=23.4.0->nvtabular->-r /root/toss-ad-click-prediction/requirements.txt (line 9)) (2.5.0)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /root/toss-ad-click-prediction/toss-ml-venv/lib/python3.10/site-packages (from distributed>=2022.11.1->merlin-core>=23.4.0->nvtabular->-r /root/toss-ad-click-prediction/requirements.txt (line 9)) (7.0.0)\n",
      "Collecting sortedcontainers>=2.0.5\n",
      "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Collecting msgpack>=1.0.2\n",
      "  Downloading msgpack-1.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (408 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m408.6/408.6 kB\u001b[0m \u001b[31m47.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of distributed to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of dask to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of rapids-dask-dependency to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of dask-cuda to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting dask-cuda>=22.12.0\n",
      "  Downloading dask_cuda-24.10.0-py3-none-any.whl (133 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.2/133.2 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting rapids-dask-dependency==24.10.*\n",
      "  Downloading rapids_dask_dependency-24.10.0-py3-none-any.whl (15 kB)\n",
      "Collecting dask-expr==1.1.14\n",
      "  Downloading dask_expr-1.1.14-py3-none-any.whl (242 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.6/242.6 kB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting dask>=2022.11.1\n",
      "  Downloading dask-2024.9.0-py3-none-any.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m70.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting distributed>=2022.11.1\n",
      "  Downloading distributed-2024.9.0-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m65.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting dask-cuda>=22.12.0\n",
      "  Downloading dask_cuda-24.8.2-py3-none-any.whl (129 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.6/129.6 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting numpy>=1.22.4\n",
      "  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m79.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting rapids-dask-dependency==24.8.*\n",
      "  Downloading rapids_dask_dependency-24.8.0-py3-none-any.whl (15 kB)\n",
      "Collecting distributed>=2022.11.1\n",
      "  Downloading distributed-2024.7.1-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting dask>=2022.11.1\n",
      "  Downloading dask-2024.7.1-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting dask-expr\n",
      "  Downloading dask_expr-2.0.0-py3-none-any.whl (3.2 kB)\n",
      "  Downloading dask_expr-1.1.21-py3-none-any.whl (244 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading dask_expr-1.1.20-py3-none-any.whl (245 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.3/245.3 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading dask_expr-1.1.18-py3-none-any.whl (244 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.5/244.5 kB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading dask_expr-1.1.16-py3-none-any.whl (243 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.2/243.2 kB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading dask_expr-1.1.15-py3-none-any.whl (242 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.7/242.7 kB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading dask_expr-1.1.13-py3-none-any.whl (242 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.6/242.6 kB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading dask_expr-1.1.12-py3-none-any.whl (242 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.6/242.6 kB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading dask_expr-1.1.11-py3-none-any.whl (242 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading dask_expr-1.1.10-py3-none-any.whl (242 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.2/242.2 kB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading dask_expr-1.1.9-py3-none-any.whl (241 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.9/241.9 kB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading dask_expr-1.1.8-py3-none-any.whl (242 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.8/242.8 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading dask_expr-1.1.7-py3-none-any.whl (241 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.7/241.7 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading dask_expr-1.1.6-py3-none-any.whl (206 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m206.6/206.6 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading dask_expr-1.1.5-py3-none-any.whl (205 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m205.9/205.9 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading dask_expr-1.1.4-py3-none-any.whl (205 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m205.9/205.9 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading dask_expr-1.1.3-py3-none-any.whl (205 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m205.7/205.7 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading dask_expr-1.1.2-py3-none-any.whl (205 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m205.5/205.5 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading dask_expr-1.1.1-py3-none-any.whl (205 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m205.4/205.4 kB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading dask_expr-1.1.0-py3-none-any.whl (205 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m205.1/205.1 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading dask_expr-1.0.14-py3-none-any.whl (195 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m195.2/195.2 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading dask_expr-1.0.13-py3-none-any.whl (195 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m195.1/195.1 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading dask_expr-1.0.12-py3-none-any.whl (194 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.3/194.3 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading dask_expr-1.0.11-py3-none-any.whl (184 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m185.0/185.0 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading dask_expr-1.0.10-py3-none-any.whl (184 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.4/184.4 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading dask_expr-1.0.9-py3-none-any.whl (184 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.8/184.8 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading dask_expr-1.0.7-py3-none-any.whl (184 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.7/184.7 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading dask_expr-1.0.6-py3-none-any.whl (184 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.1/184.1 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading dask_expr-1.0.5-py3-none-any.whl (183 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.6/183.6 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading dask_expr-1.0.4-py3-none-any.whl (180 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m180.2/180.2 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading dask_expr-1.0.3-py3-none-any.whl (180 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m180.0/180.0 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading dask_expr-1.0.2-py3-none-any.whl (179 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m180.0/180.0 kB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading dask_expr-1.0.1-py3-none-any.whl (178 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.5/178.5 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading dask_expr-1.0-py3-none-any.whl (178 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.4/178.4 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading dask_expr-0.5.3-py3-none-any.whl (171 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m171.6/171.6 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading dask_expr-0.5.2-py3-none-any.whl (168 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.9/168.9 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading dask_expr-0.5.1-py3-none-any.whl (169 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.3/169.3 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading dask_expr-0.4.2-py3-none-any.whl (165 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m165.3/165.3 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading dask_expr-0.4.1-py3-none-any.whl (164 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.9/164.9 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading dask_expr-0.4.0-py3-none-any.whl (161 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.7/161.7 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading dask_expr-0.3.5-py3-none-any.whl (145 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.2/145.2 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading dask_expr-0.3.4-py3-none-any.whl (133 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.0/134.0 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading dask_expr-0.3.3-py3-none-any.whl (121 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.0/122.0 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading dask_expr-0.3.2-py3-none-any.whl (115 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.2/115.2 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading dask_expr-0.3.1-py3-none-any.whl (111 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.5/111.5 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading dask_expr-0.3.0-py3-none-any.whl (108 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.8/108.8 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading dask_expr-0.2.9-py3-none-any.whl (104 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.5/104.5 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading dask_expr-0.2.8-py3-none-any.whl (98 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading dask_expr-0.2.7-py3-none-any.whl (95 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.8/95.8 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading dask_expr-0.2.6-py3-none-any.whl (93 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.8/93.8 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading dask_expr-0.2.5-py3-none-any.whl (92 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.5/92.5 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading dask_expr-0.2.4-py3-none-any.whl (92 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.4/92.4 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading dask_expr-0.2.3-py3-none-any.whl (91 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.7/91.7 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading dask_expr-0.2.2-py3-none-any.whl (88 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.6/88.6 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading dask_expr-0.2.1-py3-none-any.whl (87 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.7/87.7 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading dask_expr-0.2.0-py3-none-any.whl (87 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.3/87.3 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading dask_expr-0.1.12-py3-none-any.whl (83 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.8/83.8 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading dask_expr-0.1.11-py3-none-any.whl (82 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.4/82.4 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading dask_expr-0.1.10-py3-none-any.whl (82 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading dask_expr-0.1.9-py3-none-any.whl (80 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.7/80.7 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading dask_expr-0.1.8-py3-none-any.whl (79 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading dask_expr-0.1.7-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading dask_expr-0.1.6-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading dask_expr-0.1.5-py3-none-any.whl (74 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.1/74.1 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading dask_expr-0.1.4-py3-none-any.whl (73 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.8/73.8 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading dask_expr-0.1.3-py3-none-any.whl (74 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.0/74.0 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading dask_expr-0.1.2-py3-none-any.whl (71 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.3/71.3 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading dask_expr-0.1.1-py3-none-any.whl (67 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.5/67.5 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading dask_expr-0.1.0-py3-none-any.whl (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.9/61.9 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting dask-cuda>=22.12.0\n",
      "  Downloading dask_cuda-24.6.0-py3-none-any.whl (127 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.4/127.4 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting rapids-dask-dependency==24.6.*\n",
      "  Downloading rapids_dask_dependency-24.6.0-py3-none-any.whl (15 kB)\n",
      "Collecting distributed>=2022.11.1\n",
      "  Downloading distributed-2024.5.1-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m66.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting dask>=2022.11.1\n",
      "  Downloading dask-2024.5.1-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m73.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting dask-cuda>=22.12.0\n",
      "  Downloading dask_cuda-24.4.0-py3-none-any.whl (126 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.6/126.6 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting rapids-dask-dependency==24.4.*\n",
      "  Downloading rapids_dask_dependency-24.4.1-py3-none-any.whl (15 kB)\n",
      "Collecting distributed>=2022.11.1\n",
      "  Downloading distributed-2024.1.1-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m64.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting dask>=2022.11.1\n",
      "  Downloading dask-2024.1.1-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m69.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting rapids-dask-dependency==24.4.*\n",
      "  Downloading rapids_dask_dependency-24.4.0.tar.gz (2.0 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting dask-cuda>=22.12.0\n",
      "  Downloading dask_cuda-24.2.0-py3-none-any.whl (126 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.5/126.5 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting rapids-dask-dependency==24.2.*\n",
      "  Downloading rapids_dask_dependency-24.2.0-py3-none-any.whl (6.4 kB)\n",
      "Collecting llvmlite<0.45,>=0.44.0dev0\n",
      "  Downloading llvmlite-0.44.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 MB\u001b[0m \u001b[31m63.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting protobuf>=3.0.0\n",
      "  Downloading protobuf-4.21.12-cp37-abi3-manylinux2014_x86_64.whl (409 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.8/409.8 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting absl-py<3.0.0,>=0.9\n",
      "  Downloading absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.8/135.8 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting zipp>=3.20\n",
      "  Downloading zipp-3.23.0-py3-none-any.whl (10 kB)\n",
      "Collecting multidict\n",
      "  Using cached multidict-6.6.4-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (241 kB)\n",
      "Collecting h2<5,>=3.1.0\n",
      "  Downloading h2-4.3.0-py3-none-any.whl (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.8/61.8 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting hyperframe<7,>=6.1\n",
      "  Downloading hyperframe-6.1.0-py3-none-any.whl (13 kB)\n",
      "Collecting hpack<5,>=4.1\n",
      "  Downloading hpack-4.1.0-py3-none-any.whl (34 kB)\n",
      "Building wheels for collected packages: cupy, merlin-core, merlin-dataloader, betterproto\n",
      "  Building wheel for cupy (pyproject.toml) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for cupy \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[74 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m Clearing directory: /tmp/pip-install-4kr0zxzt/cupy_7002e2ed1eb64fa28aa41e839c2da955/cupy/.data\n",
      "  \u001b[31m   \u001b[0m Generating CUPY_CACHE_KEY from header files...\n",
      "  \u001b[31m   \u001b[0m CUPY_CACHE_KEY (1717 files matching /tmp/pip-install-4kr0zxzt/cupy_7002e2ed1eb64fa28aa41e839c2da955/cupy/_core/include/**): 3b917dd1428e7d3cdebf5768775abe84f10b0153\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m -------- Configuring Module: cuda --------\n",
      "  \u001b[31m   \u001b[0m /tmp/tmp6mynoxj8/a.cpp:1:10: fatal error: cublas_v2.h: No such file or directory\n",
      "  \u001b[31m   \u001b[0m     1 | #include <cublas_v2.h>\n",
      "  \u001b[31m   \u001b[0m       |          ^~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m compilation terminated.\n",
      "  \u001b[31m   \u001b[0m command '/usr/bin/g++' failed with exit code 1\n",
      "  \u001b[31m   \u001b[0m /tmp/tmp6u3rwj1g/a.cpp:2:18: fatal error: cuda_runtime_api.h: No such file or directory\n",
      "  \u001b[31m   \u001b[0m     2 |         #include <cuda_runtime_api.h>\n",
      "  \u001b[31m   \u001b[0m       |                  ^~~~~~~~~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m compilation terminated.\n",
      "  \u001b[31m   \u001b[0m **************************************************\n",
      "  \u001b[31m   \u001b[0m *** WARNING: Cannot check compute capability\n",
      "  \u001b[31m   \u001b[0m command '/usr/bin/g++' failed with exit code 1\n",
      "  \u001b[31m   \u001b[0m **************************************************\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m ************************************************************\n",
      "  \u001b[31m   \u001b[0m * CuPy Configuration Summary                               *\n",
      "  \u001b[31m   \u001b[0m ************************************************************\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Build Environment:\n",
      "  \u001b[31m   \u001b[0m   Include directories: ['/tmp/pip-install-4kr0zxzt/cupy_7002e2ed1eb64fa28aa41e839c2da955/cupy/_core/include/cupy/_cccl/libcudacxx', '/tmp/pip-install-4kr0zxzt/cupy_7002e2ed1eb64fa28aa41e839c2da955/cupy/_core/include/cupy/_cccl/thrust', '/tmp/pip-install-4kr0zxzt/cupy_7002e2ed1eb64fa28aa41e839c2da955/cupy/_core/include/cupy/_cccl/cub', '/tmp/pip-install-4kr0zxzt/cupy_7002e2ed1eb64fa28aa41e839c2da955/cupy/_core/include']\n",
      "  \u001b[31m   \u001b[0m   Library directories: []\n",
      "  \u001b[31m   \u001b[0m   nvcc command       : (not found)\n",
      "  \u001b[31m   \u001b[0m   hipcc command      : (not found)\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Environment Variables:\n",
      "  \u001b[31m   \u001b[0m   CFLAGS          : (none)\n",
      "  \u001b[31m   \u001b[0m   LDFLAGS         : (none)\n",
      "  \u001b[31m   \u001b[0m   LIBRARY_PATH    : (none)\n",
      "  \u001b[31m   \u001b[0m   CUDA_PATH       : (none)\n",
      "  \u001b[31m   \u001b[0m   NVCC            : (none)\n",
      "  \u001b[31m   \u001b[0m   HIPCC           : (none)\n",
      "  \u001b[31m   \u001b[0m   ROCM_HOME       : (none)\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Modules:\n",
      "  \u001b[31m   \u001b[0m   cuda      : No\n",
      "  \u001b[31m   \u001b[0m     -> Include files not found: ['cublas_v2.h', 'cuda.h', 'cuda_profiler_api.h', 'cuda_runtime.h', 'cufft.h', 'curand.h', 'cusparse.h']\n",
      "  \u001b[31m   \u001b[0m     -> Check your CFLAGS environment variable.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m ERROR: CUDA could not be found on your system.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m HINT: You are trying to build CuPy from source, which is NOT recommended for general use.\n",
      "  \u001b[31m   \u001b[0m       Please consider using binary packages instead.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Please refer to the Installation Guide for details:\n",
      "  \u001b[31m   \u001b[0m https://docs.cupy.dev/en/stable/install.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m ************************************************************\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"/root/toss-ad-click-prediction/toss-ml-venv/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 353, in <module>\n",
      "  \u001b[31m   \u001b[0m     main()\n",
      "  \u001b[31m   \u001b[0m   File \"/root/toss-ad-click-prediction/toss-ml-venv/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 335, in main\n",
      "  \u001b[31m   \u001b[0m     json_out['return_val'] = hook(**hook_input['kwargs'])\n",
      "  \u001b[31m   \u001b[0m   File \"/root/toss-ad-click-prediction/toss-ml-venv/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 251, in build_wheel\n",
      "  \u001b[31m   \u001b[0m     return _build_backend().build_wheel(wheel_directory, config_settings,\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-build-env-fqo6p3zn/overlay/lib/python3.10/site-packages/setuptools/build_meta.py\", line 435, in build_wheel\n",
      "  \u001b[31m   \u001b[0m     return _build(['bdist_wheel', '--dist-info-dir', str(metadata_directory)])\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-build-env-fqo6p3zn/overlay/lib/python3.10/site-packages/setuptools/build_meta.py\", line 423, in _build\n",
      "  \u001b[31m   \u001b[0m     return self._build_with_temp_dir(\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-build-env-fqo6p3zn/overlay/lib/python3.10/site-packages/setuptools/build_meta.py\", line 404, in _build_with_temp_dir\n",
      "  \u001b[31m   \u001b[0m     self.run_setup()\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-build-env-fqo6p3zn/overlay/lib/python3.10/site-packages/setuptools/build_meta.py\", line 317, in run_setup\n",
      "  \u001b[31m   \u001b[0m     exec(code, locals())\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 59, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-install-4kr0zxzt/cupy_7002e2ed1eb64fa28aa41e839c2da955/install/cupy_builder/cupy_setup_build.py\", line 562, in get_ext_modules\n",
      "  \u001b[31m   \u001b[0m     extensions = make_extensions(ctx, compiler, use_cython)\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-install-4kr0zxzt/cupy_7002e2ed1eb64fa28aa41e839c2da955/install/cupy_builder/cupy_setup_build.py\", line 403, in make_extensions\n",
      "  \u001b[31m   \u001b[0m     raise Exception('Your CUDA environment is invalid. '\n",
      "  \u001b[31m   \u001b[0m Exception: Your CUDA environment is invalid. Please check above error log.\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25h\u001b[31m  ERROR: Failed building wheel for cupy\u001b[0m\u001b[31m\n",
      "\u001b[0m  Building wheel for merlin-core (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for merlin-core: filename=merlin_core-23.8.0-py3-none-any.whl size=175365 sha256=bcf583e6f3432e4f8083ecd64b5830a8a416b848bf21c7d4a58df0efe4f9aedf\n",
      "  Stored in directory: /data/ephemeral/home/.cache/pip/wheels/8f/85/17/92fd7d5e1a56501287f492e2b99b67ee4726e953e05cd8460c\n",
      "  Building wheel for merlin-dataloader (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for merlin-dataloader: filename=merlin_dataloader-23.8.0-py3-none-any.whl size=35592 sha256=ad18cd606d3696e046afd97ea66c124e91418fdb92563feb297eb7e377c73100\n",
      "  Stored in directory: /data/ephemeral/home/.cache/pip/wheels/27/2c/f2/e2bc1dddae78192c89eb06b4890db2e4491462a47b56405d0d\n",
      "  Building wheel for betterproto (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for betterproto: filename=betterproto-1.2.5-py3-none-any.whl size=22053 sha256=9fd76f0d8bada79277c10a4854c5ae7298a39922c42123f30c9a656d7d68f85f\n",
      "  Stored in directory: /data/ephemeral/home/.cache/pip/wheels/d3/8b/bf/097193de631f010236664202ef3c05c62636abc9d2b172b458\n",
      "Successfully built merlin-core merlin-dataloader betterproto\n",
      "Failed to build cupy\n",
      "\u001b[31mERROR: Could not build wheels for cupy, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -r \"/root/toss-ad-click-prediction/requirements.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All libraries imported successfully\n",
      "NVTabular version: 23.08.00\n",
      "XGBoost version: 3.0.5\n"
     ]
    }
   ],
   "source": [
    "# Core imports\n",
    "import gc\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "import psutil\n",
    "\n",
    "# GPU libraries\n",
    "import cudf\n",
    "import cupy as cp\n",
    "\n",
    "# NVTabular\n",
    "import nvtabular as nvt\n",
    "from nvtabular import ops\n",
    "from merlin.io import Dataset\n",
    "\n",
    "# ML libraries\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "print(\"✅ All libraries imported successfully\")\n",
    "print(f\"NVTabular version: {nvt.__version__}\")\n",
    "print(f\"XGBoost version: {xgb.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📋 Configuration:\n",
      "   Input: /RSNA/toss/data/train.parquet\n",
      "   Output: /RSNA/toss/data/nvt_processed_final\n",
      "   Folds: 5\n",
      "   Force reprocess: False\n"
     ]
    }
   ],
   "source": [
    "# Configuration(DATA PATH)\n",
    "TRAIN_PATH = '/RSNA/toss/data/train.parquet'\n",
    "OUTPUT_DIR = '/RSNA/toss/data/nvt_processed_final'\n",
    "TEMP_DIR = '/tmp'\n",
    "N_FOLDS = 5\n",
    "FORCE_REPROCESS = False  # Set to True to reprocess data\n",
    "\n",
    "print(f\"📋 Configuration:\")\n",
    "print(f\"   Input: {TRAIN_PATH}\")\n",
    "print(f\"   Output: {OUTPUT_DIR}\")\n",
    "print(f\"   Folds: {N_FOLDS}\")\n",
    "print(f\"   Force reprocess: {FORCE_REPROCESS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing memory functions:\n",
      "💾 CPU: 58.5GB/472.2GB (13.1%)\n",
      "💾 GPU: 1.2GB/48.0GB\n",
      "🧹 GPU memory cleared\n"
     ]
    }
   ],
   "source": [
    "# Memory management functions\n",
    "def print_memory():\n",
    "    \"\"\"Print current memory usage\"\"\"\n",
    "    mem = psutil.virtual_memory()\n",
    "    \n",
    "    try:\n",
    "        import pynvml\n",
    "        pynvml.nvmlInit()\n",
    "        handle = pynvml.nvmlDeviceGetHandleByIndex(0)\n",
    "        gpu_info = pynvml.nvmlDeviceGetMemoryInfo(handle)\n",
    "        gpu_used = gpu_info.used / 1024**3\n",
    "        gpu_total = gpu_info.total / 1024**3\n",
    "    except:\n",
    "        gpu_used = 0\n",
    "        gpu_total = 0\n",
    "    \n",
    "    print(f\"💾 CPU: {mem.used/1024**3:.1f}GB/{mem.total/1024**3:.1f}GB ({mem.percent:.1f}%)\")\n",
    "    print(f\"💾 GPU: {gpu_used:.1f}GB/{gpu_total:.1f}GB\")\n",
    "    return mem.percent\n",
    "\n",
    "def clear_gpu_memory():\n",
    "    \"\"\"Clear GPU memory\"\"\"\n",
    "    cp.get_default_memory_pool().free_all_blocks()\n",
    "    gc.collect()\n",
    "    print(\"🧹 GPU memory cleared\")\n",
    "\n",
    "# Test memory functions\n",
    "print(\"Testing memory functions:\")\n",
    "print_memory()\n",
    "clear_gpu_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Metric functions defined\n"
     ]
    }
   ],
   "source": [
    "# Metric functions\n",
    "def calculate_weighted_logloss(y_true, y_pred, eps=1e-15):\n",
    "    \"\"\"Calculate Weighted LogLoss with 50:50 class weights\"\"\"\n",
    "    y_pred = np.clip(y_pred, eps, 1 - eps)\n",
    "    \n",
    "    mask_0 = (y_true == 0)\n",
    "    mask_1 = (y_true == 1)\n",
    "    \n",
    "    ll_0 = -np.mean(np.log(1 - y_pred[mask_0])) if mask_0.sum() > 0 else 0\n",
    "    ll_1 = -np.mean(np.log(y_pred[mask_1])) if mask_1.sum() > 0 else 0\n",
    "    \n",
    "    return 0.5 * ll_0 + 0.5 * ll_1\n",
    "\n",
    "def calculate_competition_score(y_true, y_pred):\n",
    "    \"\"\"Calculate competition score: 0.5*AP + 0.5*(1/(1+WLL))\"\"\"\n",
    "    ap = average_precision_score(y_true, y_pred)\n",
    "    wll = calculate_weighted_logloss(y_true, y_pred)\n",
    "    score = 0.5 * ap + 0.5 * (1 / (1 + wll))\n",
    "    return score, ap, wll\n",
    "\n",
    "print(\"✅ Metric functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔧 Creating XGBoost-optimized workflow...\n",
      "   Categorical: 5 columns\n",
      "   Continuous: 112 columns\n",
      "   Total features: 117\n",
      "   ✅ Workflow created (no normalization for tree models)\n",
      "✅ Workflow creation tested successfully\n"
     ]
    }
   ],
   "source": [
    "def create_workflow():\n",
    "    \"\"\"Create NVTabular workflow optimized for XGBoost\"\"\"\n",
    "    print(\"\\n🔧 Creating XGBoost-optimized workflow...\")\n",
    "    \n",
    "    # TRUE CATEGORICAL COLUMNS (only 5)\n",
    "    true_categorical = ['gender', 'age_group', 'inventory_id', 'day_of_week', 'hour']\n",
    "    \n",
    "    # CONTINUOUS COLUMNS (112 total)\n",
    "    all_continuous = (\n",
    "        [f'feat_a_{i}' for i in range(1, 19)] +  # 18\n",
    "        [f'feat_b_{i}' for i in range(1, 7)] +   # 6\n",
    "        [f'feat_c_{i}' for i in range(1, 9)] +   # 8\n",
    "        [f'feat_d_{i}' for i in range(1, 7)] +   # 6\n",
    "        [f'feat_e_{i}' for i in range(1, 11)] +  # 10\n",
    "        [f'history_a_{i}' for i in range(1, 8)] +  # 7\n",
    "        [f'history_b_{i}' for i in range(1, 31)] + # 30\n",
    "        [f'l_feat_{i}' for i in range(1, 28)]      # 27\n",
    "    )\n",
    "    \n",
    "    print(f\"   Categorical: {len(true_categorical)} columns\")\n",
    "    print(f\"   Continuous: {len(all_continuous)} columns\")\n",
    "    print(f\"   Total features: {len(true_categorical) + len(all_continuous)}\")\n",
    "    \n",
    "    # Minimal preprocessing for XGBoost\n",
    "    cat_features = true_categorical >> ops.Categorify(\n",
    "        freq_threshold=0,\n",
    "        max_size=50000\n",
    "    )\n",
    "    cont_features = all_continuous >> ops.FillMissing(fill_val=0)\n",
    "    \n",
    "    workflow = nvt.Workflow(cat_features + cont_features + ['clicked'])\n",
    "    \n",
    "    print(\"   ✅ Workflow created (no normalization for tree models)\")\n",
    "    return workflow\n",
    "\n",
    "# Test workflow creation\n",
    "test_workflow = create_workflow()\n",
    "print(\"✅ Workflow creation tested successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "🚀 NVTabular Data Processing\n",
      "======================================================================\n",
      "✅ Using existing processed data from /RSNA/toss/data/nvt_processed_final\n"
     ]
    }
   ],
   "source": [
    "def process_data():\n",
    "    \"\"\"Process data with NVTabular\"\"\"\n",
    "    import shutil\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"🚀 NVTabular Data Processing\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Check if already processed\n",
    "    if os.path.exists(OUTPUT_DIR) and not FORCE_REPROCESS:\n",
    "        try:\n",
    "            test_dataset = Dataset(OUTPUT_DIR, engine='parquet')\n",
    "            print(f\"✅ Using existing processed data from {OUTPUT_DIR}\")\n",
    "            return OUTPUT_DIR\n",
    "        except:\n",
    "            print(f\"⚠️ Existing data corrupted, reprocessing...\")\n",
    "            shutil.rmtree(OUTPUT_DIR)\n",
    "    \n",
    "    # Clear existing if needed\n",
    "    if os.path.exists(OUTPUT_DIR):\n",
    "        print(f\"🗑️ Removing existing directory {OUTPUT_DIR}\")\n",
    "        shutil.rmtree(OUTPUT_DIR)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    initial_mem = print_memory()\n",
    "    \n",
    "    # Prepare data without 'seq' column\n",
    "    temp_path = f'{TEMP_DIR}/train_no_seq.parquet'\n",
    "    if not os.path.exists(temp_path):\n",
    "        print(\"\\n📋 Creating temp file without 'seq' column...\")\n",
    "        pf = pq.ParquetFile(TRAIN_PATH)\n",
    "        cols = [c for c in pf.schema.names if c != 'seq']\n",
    "        print(f\"   Total columns: {len(pf.schema.names)}\")\n",
    "        print(f\"   Using columns: {len(cols)} (excluded 'seq')\")\n",
    "        \n",
    "        df = pd.read_parquet(TRAIN_PATH, columns=cols)\n",
    "        print(f\"   Loaded {len(df):,} rows\")\n",
    "        df.to_parquet(temp_path, index=False)\n",
    "        del df\n",
    "        gc.collect()\n",
    "        print(\"   ✅ Temp file created\")\n",
    "    else:\n",
    "        print(f\"✅ Using existing temp file: {temp_path}\")\n",
    "    \n",
    "    # Create dataset with small partitions\n",
    "    print(\"\\n📦 Creating NVTabular Dataset...\")\n",
    "    print(\"   Using 32MB partitions for memory efficiency\")\n",
    "    clear_gpu_memory()\n",
    "    \n",
    "    dataset = Dataset(\n",
    "        temp_path,\n",
    "        engine='parquet',\n",
    "        part_size='32MB'  #change size based on your environment\n",
    "    )\n",
    "    print(\"   ✅ Dataset created\")\n",
    "    \n",
    "    # Create and fit workflow\n",
    "    print(\"\\n📊 Fitting workflow...\")\n",
    "    workflow = create_workflow()\n",
    "    workflow.fit(dataset)\n",
    "    print(\"   ✅ Workflow fitted\")\n",
    "    \n",
    "    # Transform and save\n",
    "    print(f\"\\n💾 Transforming and saving to {OUTPUT_DIR}...\")\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "    \n",
    "    clear_gpu_memory()\n",
    "    \n",
    "    try:\n",
    "        workflow.transform(dataset).to_parquet(\n",
    "            output_path=OUTPUT_DIR,\n",
    "            shuffle=nvt.io.Shuffle.PER_PARTITION,\n",
    "            out_files_per_proc=8\n",
    "        )\n",
    "        \n",
    "        workflow_path = f'{OUTPUT_DIR}/workflow'\n",
    "        workflow.save(workflow_path)\n",
    "        print(f\"   ✅ Data processed and saved\")\n",
    "        print(f\"   ✅ Workflow saved to {workflow_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error during processing: {e}\")\n",
    "        if os.path.exists(OUTPUT_DIR):\n",
    "            shutil.rmtree(OUTPUT_DIR)\n",
    "        raise\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    final_mem = print_memory()\n",
    "    \n",
    "    print(f\"\\n✅ Processing complete!\")\n",
    "    print(f\"   Time: {elapsed:.1f}s\")\n",
    "    print(f\"   Memory increase: +{final_mem - initial_mem:.1f}%\")\n",
    "    \n",
    "    clear_gpu_memory()\n",
    "    return OUTPUT_DIR\n",
    "\n",
    "# Process data\n",
    "processed_dir = process_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "🔄 Stratified KFold Cross-Validation\n",
      "======================================================================\n",
      "\n",
      "📦 Loading processed data...\n",
      "   Converting to GPU DataFrame...\n",
      "   ✅ Loaded 10,704,179 rows x 118 columns\n",
      "   Time: 2.3s\n",
      "💾 CPU: 58.2GB/472.2GB (13.0%)\n",
      "💾 GPU: 6.4GB/48.0GB\n",
      "\n",
      "📊 Preparing data for XGBoost...\n",
      "   Shape: (10704179, 117)\n",
      "   Features: 117\n",
      "   Samples: 10,704,179\n",
      "\n",
      "📊 Class distribution:\n",
      "   Positive ratio: 0.0191\n",
      "   Scale pos weight: 51.43\n",
      "🧹 GPU memory cleared\n",
      "\n",
      "🔄 Starting cross-validation...\n",
      "\n",
      "📍 Fold 1/5\n",
      "   Train: 8,563,343 | Val: 2,140,836\n",
      "   Training...\n",
      "   📊 Results:\n",
      "      Score: 0.353420\n",
      "      AP: 0.081463\n",
      "      WLL: 0.599035\n",
      "      Best iteration: 199\n",
      "   ⏱️ Time: 26.0s\n",
      "🧹 GPU memory cleared\n",
      "\n",
      "📍 Fold 2/5\n",
      "   Train: 8,563,343 | Val: 2,140,836\n",
      "   Training...\n",
      "   📊 Results:\n",
      "      Score: 0.354111\n",
      "      AP: 0.082687\n",
      "      WLL: 0.598632\n",
      "      Best iteration: 199\n",
      "   ⏱️ Time: 26.1s\n",
      "🧹 GPU memory cleared\n",
      "\n",
      "📍 Fold 3/5\n",
      "   Train: 8,563,343 | Val: 2,140,836\n",
      "   Training...\n",
      "   📊 Results:\n",
      "      Score: 0.352495\n",
      "      AP: 0.080028\n",
      "      WLL: 0.600096\n",
      "      Best iteration: 199\n",
      "   ⏱️ Time: 26.0s\n",
      "🧹 GPU memory cleared\n",
      "\n",
      "📍 Fold 4/5\n",
      "   Train: 8,563,343 | Val: 2,140,836\n",
      "   Training...\n",
      "   📊 Results:\n",
      "      Score: 0.353601\n",
      "      AP: 0.081818\n",
      "      WLL: 0.599018\n",
      "      Best iteration: 199\n",
      "   ⏱️ Time: 25.8s\n",
      "🧹 GPU memory cleared\n",
      "\n",
      "📍 Fold 5/5\n",
      "   Train: 8,563,344 | Val: 2,140,835\n",
      "   Training...\n",
      "   📊 Results:\n",
      "      Score: 0.352288\n",
      "      AP: 0.079672\n",
      "      WLL: 0.600247\n",
      "      Best iteration: 199\n",
      "   ⏱️ Time: 26.0s\n",
      "🧹 GPU memory cleared\n",
      "\n",
      "======================================================================\n",
      "📊 Final Cross-Validation Results\n",
      "======================================================================\n",
      "\n",
      "🏆 Competition Score: 0.353183 ± 0.000688\n",
      "📈 Average Precision: 0.081133 ± 0.001127\n",
      "📉 Weighted LogLoss: 0.599406 ± 0.000644\n",
      "\n",
      "All fold scores: ['0.353420', '0.354111', '0.352495', '0.353601', '0.352288']\n"
     ]
    }
   ],
   "source": [
    "def run_cv(processed_dir, n_folds=5):\n",
    "    \"\"\"Run stratified cross-validation\"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"🔄 Stratified KFold Cross-Validation\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Load processed data\n",
    "    print(\"\\n📦 Loading processed data...\")\n",
    "    start_load = time.time()\n",
    "    \n",
    "    try:\n",
    "        dataset = Dataset(processed_dir, engine='parquet', part_size='256MB')\n",
    "        print(\"   Converting to GPU DataFrame...\")\n",
    "        gdf = dataset.to_ddf().compute()\n",
    "        print(f\"   ✅ Loaded {len(gdf):,} rows x {len(gdf.columns)} columns\")\n",
    "        print(f\"   Time: {time.time() - start_load:.1f}s\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error loading data: {e}\")\n",
    "        return None\n",
    "    \n",
    "    print_memory()\n",
    "    \n",
    "    # Prepare data\n",
    "    print(\"\\n📊 Preparing data for XGBoost...\")\n",
    "    y = gdf['clicked'].to_numpy()\n",
    "    X = gdf.drop('clicked', axis=1)\n",
    "    \n",
    "    # Convert to float32\n",
    "    for col in X.columns:\n",
    "        if X[col].dtype != 'float32':\n",
    "            X[col] = X[col].astype('float32')\n",
    "    \n",
    "    X_np = X.to_numpy()\n",
    "    print(f\"   Shape: {X_np.shape}\")\n",
    "    print(f\"   Features: {X.shape[1]}\")\n",
    "    print(f\"   Samples: {X.shape[0]:,}\")\n",
    "    \n",
    "    # Class distribution\n",
    "    pos_ratio = y.mean()\n",
    "    scale_pos_weight = (1 - pos_ratio) / pos_ratio\n",
    "    print(f\"\\n📊 Class distribution:\")\n",
    "    print(f\"   Positive ratio: {pos_ratio:.4f}\")\n",
    "    print(f\"   Scale pos weight: {scale_pos_weight:.2f}\")\n",
    "    \n",
    "    del X, gdf\n",
    "    clear_gpu_memory()\n",
    "    \n",
    "    # XGBoost parameters\n",
    "    params = {\n",
    "        'objective': 'binary:logistic',\n",
    "        'tree_method': 'gpu_hist',\n",
    "        'max_depth': 8,\n",
    "        'learning_rate': 0.1,\n",
    "        'subsample': 0.8,\n",
    "        'colsample_bytree': 0.8,\n",
    "        'scale_pos_weight': scale_pos_weight,\n",
    "        'gpu_id': 0,\n",
    "        'verbosity': 0,\n",
    "        'seed': 42\n",
    "    }\n",
    "    \n",
    "    # Cross-validation\n",
    "    print(\"\\n🔄 Starting cross-validation...\")\n",
    "    skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "    \n",
    "    cv_scores = []\n",
    "    cv_ap = []\n",
    "    cv_wll = []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X_np, y), 1):\n",
    "        print(f\"\\n📍 Fold {fold}/{n_folds}\")\n",
    "        fold_start = time.time()\n",
    "        \n",
    "        # Create DMatrix\n",
    "        print(f\"   Train: {len(train_idx):,} | Val: {len(val_idx):,}\")\n",
    "        dtrain = xgb.DMatrix(X_np[train_idx], label=y[train_idx])\n",
    "        dval = xgb.DMatrix(X_np[val_idx], label=y[val_idx])\n",
    "        \n",
    "        # Train\n",
    "        print(\"   Training...\")\n",
    "        model = xgb.train(\n",
    "            params, dtrain,\n",
    "            num_boost_round=200,\n",
    "            evals=[(dval, 'val')],\n",
    "            early_stopping_rounds=20,\n",
    "            verbose_eval=False\n",
    "        )\n",
    "        \n",
    "        # Evaluate\n",
    "        y_pred = model.predict(dval)\n",
    "        score, ap, wll = calculate_competition_score(y[val_idx], y_pred)\n",
    "        \n",
    "        cv_scores.append(score)\n",
    "        cv_ap.append(ap)\n",
    "        cv_wll.append(wll)\n",
    "        \n",
    "        print(f\"   📊 Results:\")\n",
    "        print(f\"      Score: {score:.6f}\")\n",
    "        print(f\"      AP: {ap:.6f}\")\n",
    "        print(f\"      WLL: {wll:.6f}\")\n",
    "        print(f\"      Best iteration: {model.best_iteration}\")\n",
    "        print(f\"   ⏱️ Time: {time.time() - fold_start:.1f}s\")\n",
    "        \n",
    "        # Cleanup\n",
    "        del dtrain, dval, model\n",
    "        clear_gpu_memory()\n",
    "    \n",
    "    # Final results\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"📊 Final Cross-Validation Results\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    print(f\"\\n🏆 Competition Score: {np.mean(cv_scores):.6f} ± {np.std(cv_scores):.6f}\")\n",
    "    print(f\"📈 Average Precision: {np.mean(cv_ap):.6f} ± {np.std(cv_ap):.6f}\")\n",
    "    print(f\"📉 Weighted LogLoss: {np.mean(cv_wll):.6f} ± {np.std(cv_wll):.6f}\")\n",
    "    \n",
    "    print(f\"\\nAll fold scores: {[f'{s:.6f}' for s in cv_scores]}\")\n",
    "    \n",
    "    return cv_scores\n",
    "\n",
    "# Run cross-validation\n",
    "cv_scores = run_cv(processed_dir, N_FOLDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉\n",
      "COMPLETE!\n",
      "🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉\n",
      "\n",
      "✅ Final CV Score: 0.353183 ± 0.000688\n",
      "✅ Full dataset processed (10.7M rows)\n",
      "✅ XGBoost-optimized preprocessing (no normalization)\n",
      "✅ Memory-efficient with small partitions\n",
      "======================================================================\n",
      "🧹 GPU memory cleared\n",
      "\n",
      "🧹 Final cleanup complete\n",
      "💾 CPU: 59.1GB/472.2GB (13.2%)\n",
      "💾 GPU: 1.3GB/48.0GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "13.2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Final summary\n",
    "if cv_scores:\n",
    "    print(\"\\n\" + \"🎉\"*35)\n",
    "    print(\"COMPLETE!\")\n",
    "    print(\"🎉\"*35)\n",
    "    print(f\"\\n✅ Final CV Score: {np.mean(cv_scores):.6f} ± {np.std(cv_scores):.6f}\")\n",
    "    print(\"✅ Full dataset processed (10.7M rows)\")\n",
    "    print(\"✅ XGBoost-optimized preprocessing (no normalization)\")\n",
    "    print(\"✅ Memory-efficient with small partitions\")\n",
    "    print(\"=\"*70)\n",
    "else:\n",
    "    print(\"\\n⚠️ Cross-validation did not complete. Please check for errors above.\")\n",
    "\n",
    "# Final cleanup\n",
    "clear_gpu_memory()\n",
    "print(\"\\n🧹 Final cleanup complete\")\n",
    "print_memory()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "toss-ml-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
