#!/usr/bin/env python3
"""
í•™ìŠµ ì™„ë£Œ í›„ visualizationë§Œ ë‹¤ì‹œ ì‹¤í–‰í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸
ì´ë¯¸ í›ˆë ¨ëœ ëª¨ë¸ê³¼ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
"""
import json
import os
import sys
from pathlib import Path
import torch
import numpy as np
import pandas as pd

# í˜„ì¬ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

BASE_DIR = Path(__file__).resolve().parent

from config import CFG, device
from data_loader import load_data, get_feature_columns, ClickDataset
from inference import load_models, predict, create_submission
from visualization import EnsembleVisualizer

def analyze_low_importance_features(
    global_series: pd.Series,
    *,
    bottom_percentile: float = 10.0,
    min_threshold: float = None,
    min_features_to_keep: int = 50,
    safe_mode: bool = True,
) -> dict:
    """
    ë³´ìˆ˜ì ìœ¼ë¡œ ë‚®ì€ ì¤‘ìš”ë„ ë³€ìˆ˜ë“¤ì„ ì‹ë³„í•©ë‹ˆë‹¤.
    
    Args:
        global_series: ê¸€ë¡œë²Œ feature importance Series
        bottom_percentile: ì œê±°í•  í•˜ìœ„ í¼ì„¼íŠ¸ (5.0-15.0 ê¶Œì¥)
        min_threshold: ì ˆëŒ€ì  ì„ê³„ê°’ (ì´ ê°’ ì´í•˜ëŠ” ì œê±° í›„ë³´)
        min_features_to_keep: ìµœì†Œ ìœ ì§€í•  ë³€ìˆ˜ ê°œìˆ˜
        safe_mode: ì•ˆì „ ëª¨ë“œ (ê·¹ë‹¨ì  ì œê±° ë°©ì§€)
        
    Returns:
        dict: ë¶„ì„ ê²°ê³¼ ë° ì œê±° í›„ë³´ ë³€ìˆ˜ë“¤
    """
    import pandas as pd
    import numpy as np
    
    if global_series.empty:
        return {'candidates': [], 'summary': 'No features to analyze'}
    
    total_features = len(global_series)
    
    # ì•ˆì „ ëª¨ë“œì—ì„œ extreme ì„¤ì • ë°©ì§€
    if safe_mode:
        bottom_percentile = min(bottom_percentile, 15.0)  # ìµœëŒ€ 15%ê¹Œì§€ë§Œ
        min_features_to_keep = max(min_features_to_keep, total_features // 2)
    
    # Percentile ê¸°ë°˜ ì„ê³„ê°’ ê³„ì‚°
    percentile_threshold = np.percentile(global_series.values, bottom_percentile)
    
    # ìµœì¢… ì„ê³„ê°’ ê²°ì •
    if min_threshold is not None:
        final_threshold = max(percentile_threshold, min_threshold)
    else:
        final_threshold = percentile_threshold
    
    # ì œê±° í›„ë³´ ì‹ë³„
    candidates = global_series[global_series <= final_threshold].sort_values()
    
    # ì•ˆì „ì¥ì¹˜: ë„ˆë¬´ ë§ì´ ì œê±°ë˜ëŠ” ê²ƒ ë°©ì§€
    max_to_remove = total_features - min_features_to_keep
    if len(candidates) > max_to_remove:
        candidates = candidates.head(max_to_remove)
    
    # í†µê³„ ê³„ì‚°
    kept_features = total_features - len(candidates)
    
    return {
        'candidates': candidates.index.tolist(),
        'candidates_series': candidates,
        'total_features': total_features,
        'candidates_count': len(candidates),
        'kept_features': kept_features,
        'removal_percentage': len(candidates) / total_features * 100,
        'threshold_used': final_threshold,
        'safe_to_remove': len(candidates) <= max_to_remove and len(candidates) < total_features * 0.15
    }

def main():
    print("ğŸ¯ Visualization ì¬ì‹¤í–‰ ì‹œì‘...")
    
    # 1. ê¸°ë³¸ ë°ì´í„° ë¡œë”© (feature ì •ë³´ë§Œ í•„ìš”)
    print("1. ë°ì´í„° ë° feature ì •ë³´ ë¡œë”©...")
    train_df, test_df = load_data(CFG['DATA_PATH'])
    numeric_cols, categorical_info, seq_col, target_col = get_feature_columns(train_df)
    
    # 2. í•™ìŠµëœ ëª¨ë¸ë“¤ ë¡œë“œ
    print("2. í•™ìŠµëœ ëª¨ë¸ë“¤ ë¡œë”©...")
    
    # ëª¨ë¸ ê²½ë¡œë“¤ì„ ìë™ìœ¼ë¡œ ì°¾ê¸°
    model_dir = Path(CFG['CHECKPOINT_DIR'])
    fold_model_paths = []
    
    # best_dcn_model_fold_*.pth íŒŒì¼ë“¤ ì°¾ê¸°
    for i in range(1, CFG['FOLDS'] + 1):
        model_path = model_dir / f"best_dcn_model_fold_{i}.pth"
        if model_path.exists():
            fold_model_paths.append(str(model_path))
            print(f"   âœ“ Fold {i} ëª¨ë¸ ë°œê²¬: {model_path}")
        else:
            print(f"   âš ï¸  Fold {i} ëª¨ë¸ ì—†ìŒ: {model_path}")
    
    if not fold_model_paths:
        print("âŒ í•™ìŠµëœ ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
        return
    
    # ëª¨ë¸ë“¤ì„ ë©”ëª¨ë¦¬ì— ë¡œë“œ
    ensemble_models = load_models(
        model_paths=fold_model_paths,
        numeric_cols=numeric_cols,
        categorical_info=categorical_info,
        device=device,
    )
    print(f"   âœ“ {len(ensemble_models)}ê°œ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
    
    # 3. í…ŒìŠ¤íŠ¸ ì˜ˆì¸¡ ìˆ˜í–‰ (visualizationì— í•„ìš”í•œ ë°ì´í„° ìƒì„±)
    print("3. í…ŒìŠ¤íŠ¸ ì˜ˆì¸¡ ìˆ˜í–‰...")
    
    # Calibration ì„¤ì •
    calibration_temperature = None
    calibration_path_str = CFG.get('CALIBRATION_PATH')
    if calibration_path_str:
        calibration_path = (BASE_DIR / calibration_path_str).resolve()
        if calibration_path.exists():
            try:
                with calibration_path.open('r', encoding='utf-8') as f:
                    calibration_payload = json.load(f)
                calibration_temperature = float(calibration_payload.get('temperature'))
                print(f"   âœ“ Temperature calibration: T={calibration_temperature:.4f}")
            except Exception as e:
                print(f"   âš ï¸  Calibration íŒŒì¼ ì˜¤ë¥˜: {e}")
    
    # ì˜ˆì¸¡ ì‹¤í–‰
    test_pd = test_df.to_pandas()
    ensemble_preds, fold_preds = predict(
        model=ensemble_models,
        test_df=test_pd,
        numeric_cols=numeric_cols,
        categorical_info=categorical_info,
        seq_col=seq_col,
        batch_size=CFG['BATCH_SIZE'],
        device=device,
        temperature=calibration_temperature,
    )
    print(f"   âœ“ ì˜ˆì¸¡ ì™„ë£Œ: {ensemble_preds.shape}")
    
    # 4. Visualization ì‹¤í–‰
    print("4. Visualization ìƒì„±...")
    
    diagnostics_dir = Path(CFG['OUTPUT_PATH']) / "diagnostics"
    visualizer = EnsembleVisualizer(diagnostics_dir)
    
    # 4-1. í™•ë¥  ë¶„í¬ ê·¸ë˜í”„
    probability_plot_path = visualizer.plot_probability_distribution(ensemble_preds)
    print(f"   âœ“ í™•ë¥  ë¶„í¬: {probability_plot_path}")
    
    # 4-2. Fold ë¹„êµ ê·¸ë˜í”„
    fold_labels = [f"Fold {i+1}" for i in range(len(fold_model_paths))]
    fold_comparison_path, inspected_sample_index = visualizer.plot_fold_comparison(
        fold_predictions=fold_preds,
        ensemble_predictions=ensemble_preds,
        fold_labels=fold_labels,
    )
    print(f"   âœ“ Fold ë¹„êµ (sample {inspected_sample_index}): {fold_comparison_path}")
    
    # 4-3. Feature contribution ë¶„ì„ (ì£¼ìš” ìˆ˜ì • ë¶€ë¶„)
    print("   ğŸ“Š Feature contribution ë¶„ì„ ì‹œì‘...")
    
    # í›ˆë ¨ ë°ì´í„°ì…‹ ìƒì„±
    train_dataset = ClickDataset(
        train_df,
        numeric_cols,
        seq_col,
        target_col=target_col,
        categorical_info=categorical_info,
        has_target=True,
    )
    
    # ê°€ì¥ ì¢‹ì€ ëª¨ë¸ ì„ íƒ (ì²« ë²ˆì§¸ ëª¨ë¸ ì‚¬ìš©)
    explanation_model = ensemble_models[0]
    
    # ì–‘ì„± ìƒ˜í”Œ ì¤‘ì—ì„œ ì„¤ëª…í•  ìƒ˜í”Œ ì„ íƒ
    positive_indices = (
        train_dataset.df.index[train_dataset.df[target_col] == 1].tolist()
        if target_col in train_dataset.df.columns
        else []
    )
    local_explain_index = int(positive_indices[0]) if positive_indices else 0
    
    # Feature contribution ë¶„ì„ ì‹¤í–‰
    try:
        feature_contrib_outputs = visualizer.plot_feature_contributions(
            model=explanation_model,
            dataset=train_dataset,
            numeric_cols=numeric_cols,
            device=device,
            sample_index=local_explain_index,
            global_sample_size=min(len(train_dataset), 256),
            filename_prefix="feature_contributions",
        )
        
        if feature_contrib_outputs:
            print("   âœ“ Feature contribution ë¶„ì„ ì™„ë£Œ!")
            
            # ê²°ê³¼ ì¶œë ¥
            local_prob = feature_contrib_outputs.get('probability')
            prob_display = f"{local_prob:.3f}" if isinstance(local_prob, (int, float)) else 'n/a'
            
            print(f"   ğŸ“ ë¡œì»¬ ë¶„ì„ (sample {local_explain_index}, p={prob_display}):")
            local_series = feature_contrib_outputs['local_series'].head(5)
            for feature, value in local_series.items():
                print(f"       â€¢ {feature}: {value:+.4f}")
            
            print("   ğŸŒ ê¸€ë¡œë²Œ ì¤‘ìš” features:")
            global_series = feature_contrib_outputs['global_series'].head(5)
            for feature, value in global_series.items():
                print(f"       â€¢ {feature}: {value:.4f}")
            
            # 6. ë‚®ì€ ì¤‘ìš”ë„ ë³€ìˆ˜ ì‹ë³„ ë¶„ì„
            print("\n6. ë‚®ì€ ì¤‘ìš”ë„ ë³€ìˆ˜ ì‹ë³„...")
            try:
                full_global_series = feature_contrib_outputs['global_series']
                
                # ë³´ìˆ˜ì  ì ‘ê·¼: 5%, 10% ë‘ ê°€ì§€ ì‹œë‚˜ë¦¬ì˜¤ ë¶„ì„
                scenarios = [
                    {'percentile': 5.0, 'name': 'ë§¤ìš° ë³´ìˆ˜ì '},
                    {'percentile': 10.0, 'name': 'ë³´ìˆ˜ì '},
                ]
                
                for scenario in scenarios:
                    analysis = analyze_low_importance_features(
                        full_global_series, 
                        bottom_percentile=scenario['percentile']
                    )
                    
                    print(f"\n   ğŸ” {scenario['name']} ì‹œë‚˜ë¦¬ì˜¤ (í•˜ìœ„ {scenario['percentile']}%):")
                    print(f"       â€¢ ì „ì²´ ë³€ìˆ˜: {analysis['total_features']}ê°œ")
                    print(f"       â€¢ ì œê±° í›„ë³´: {analysis['candidates_count']}ê°œ ({analysis['removal_percentage']:.1f}%)")
                    print(f"       â€¢ ìœ ì§€ ë³€ìˆ˜: {analysis['kept_features']}ê°œ")
                    print(f"       â€¢ ì„ê³„ê°’: {analysis['threshold_used']:.6f}")
                    
                    if analysis['candidates_count'] > 0:
                        candidates_series = analysis['candidates_series']
                        print(f"       â€¢ ì œê±° í›„ë³´ ì¤‘ìš”ë„ ë²”ìœ„: {candidates_series.min():.6f} ~ {candidates_series.max():.6f}")
                        
                        if analysis['candidates_count'] >= 5:
                            print("       â€¢ ì œê±° í›„ë³´ ë³€ìˆ˜ë“¤:")
                            for var_name, importance in candidates_series.items():
                                print(f"           - {var_name}: {importance:.6f}")
                        else:
                            print(f"       â€¢ ê°€ì¥ ë‚®ì€ 5ê°œ ë³€ìˆ˜:")
                            for var_name, importance in candidates_series.head(5).items():
                                print(f"           - {var_name}: {importance:.6f}")
                    
                    # ì•ˆì „ì„± í‰ê°€
                    safety_status = "âœ… ì•ˆì „" if analysis['safe_to_remove'] else "âš ï¸ ì£¼ì˜"
                    print(f"       â€¢ ì œê±° ì•ˆì „ì„±: {safety_status}")
                
                
            except Exception as e:
                print(f"   âŒ ë‚®ì€ ì¤‘ìš”ë„ ë³€ìˆ˜ ë¶„ì„ ì‹¤íŒ¨: {e}")
                
        else:
            print("   âš ï¸ Feature contribution ê²°ê³¼ ì—†ìŒ")
            
    except Exception as e:
        print(f"   âŒ Feature contribution ë¶„ì„ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
    
    # 5. ì œì¶œ íŒŒì¼ ìƒì„±
    print("5. ì œì¶œ íŒŒì¼ ìƒì„±...")
    
    os.makedirs(CFG['OUTPUT_PATH'], exist_ok=True)
    submission_filename = "dcn_submission0925.csv"
    submission_path = os.path.join(CFG['OUTPUT_PATH'], submission_filename)
    
    try:
        submission = create_submission(
            test_preds=ensemble_preds,
            sample_submission_path='../data/sample_submission.csv',
            output_path=submission_path
        )
        
        print(f"   âœ“ ì œì¶œ íŒŒì¼ ì €ì¥: {submission_path}")
        print(f"   âœ“ ì˜ˆì¸¡ ê²°ê³¼ shape: {ensemble_preds.shape}")
        print(
            f"   âœ“ ì˜ˆì¸¡ê°’ ë²”ìœ„: ["
            f"{ensemble_preds.min():.4f}, {ensemble_preds.max():.4f}]"
        )
        
    except Exception as e:
        print(f"   âŒ ì œì¶œ íŒŒì¼ ìƒì„± ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
    
    # GPU ë©”ëª¨ë¦¬ ì •ë¦¬
    torch.cuda.empty_cache()
    
    print("\nğŸ‰ ì „ì²´ ì¬ì‹¤í–‰ ì™„ë£Œ!")
    print("=" * 50)
    print("ğŸ“‚ ìƒì„±ëœ íŒŒì¼ë“¤:")
    print(f"   â€¢ ì œì¶œ íŒŒì¼: {submission_path}")
    print(f"   â€¢ ì§„ë‹¨ ê·¸ë˜í”„ë“¤: {diagnostics_dir}/")
    print("=" * 50)

if __name__ == "__main__":
    main()